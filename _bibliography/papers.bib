@InProceedings{10.1007/978-3-031-19781-9_6,
author="Liu, Bo
and Yang, Fan
and Bi, Xiuli
and Xiao, Bin
and Li, Weisheng
and Gao, Xinbo",
editor="Avidan, Shai
and Brostow, Gabriel
and Ciss{\'e}, Moustapha
and Farinella, Giovanni Maria
and Hassner, Tal",
title="Detecting Generated Images by Real Images",
booktitle="Computer Vision -- ECCV 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="95--110",
abstract="The widespread of generative models have called into question the authenticity of many things on the web. In this situation, the task of image forensics is urgent. The existing methods examine generated images and claim a forgery by detecting visual artifacts or invisible patterns, resulting in generalization issues. We observed that the noise pattern of real images exhibits similar characteristics in the frequency domain, while the generated images are far different. Therefore, we can perform image authentication by checking whether an image follows the patterns of authentic images. The experiments show that a simple classifier using noise patterns can easily detect a wide range of generative models, including GAN and flow-based models. Our method achieves state-of-the-art performance on both low- and high-resolution images from a wide range of generative models and shows superior generalization ability to unseen models. The code is available at https://github.com/Tangsenghenshou/Detecting-Generated-Images-by-Real-Images.",
isbn="978-3-031-19781-9"
}

@ARTICLE{9878360,
  author={Bi, Xiuli and Shang, Yixuan and Liu, Bo and Xiao, Bin and Li, Weisheng and Gao, Xinbo},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={A Versatile Detection Method for Various Contrast Enhancement Manipulations}, 
  year={2023},
  volume={33},
  number={2},
  pages={491-504},
  abstract={Contrast enhancement manipulation is a common method to improve the visual effect of an image. Meanwhile, it can also be considered a type of global image forgery because it changes the image’s visual appearance without alerting its semantics. Moreover, for local image forgery, a tampered image may be composited by images with different contrast enhancement manipulations or post-processed by a contrast enhancement manipulation to conceal the trails of tampering. Therefore, contrast enhancement manipulation detection is critical to global image forgery detection. The existing methods can only detect a particular type of contrast enhancement manipulation, such as gamma correction or histogram equalization. To break this limitation, we propose the zero-gap spans (ZGS) as the fingerprint to explore the traces of contrast enhancement manipulations. Based on ZGS, various contrast enhancement manipulations can be distinguished by a simple classification method at image-level and patch-level; different gamma corrections can be identified, and their gamma value can be estimated. Experimental results indicate that the proposed ZGS-based classification method can achieve and maintain good classification performance under different cases (gamma correction, simple histogram equalization, modified histogram equalization techniques). Meanwhile, ZGS can estimate the gamma value with the mean squared error (MSE) below 0.1156. For the local forgery images, the proposed ZGS also can be utilized to locate the regions with different contrast enhancement manipulations.},
  keywords={},
  doi={10.1109/TCSVT.2022.3204789},
  ISSN={1558-2205},
  month={Feb},}
  
@Article{rs14174219,
AUTHOR = {Liu, Bo and Hu, Jinwu and Bi, Xiuli and Li, Weisheng and Gao, Xinbo},
TITLE = {PGNet: Positioning Guidance Network for Semantic Segmentation of Very-High-Resolution Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {17},
ARTICLE-NUMBER = {4219},
URL = {https://www.mdpi.com/2072-4292/14/17/4219},
ISSN = {2072-4292},
ABSTRACT = {Semantic segmentation of very-high-resolution (VHR) remote sensing images plays an important role in the intelligent interpretation of remote sensing since it predicts pixel-level labels to the images. Although many semantic segmentation methods of VHR remote sensing images have emerged recently and achieved good results, it is still a challenging task because the objects of VHR remote sensing images show large intra-class and small inter-class variations, and their size varies in a large range. Therefore, we proposed a novel semantic segmentation framework for VHR remote sensing images, called Positioning Guidance Network (PGNet), which consists of the feature extractor, a positioning guiding module (PGM), and a self-multiscale collection module (SMCM). First, the PGM can extract long-range dependence and global context information with the help of the transformer architecture and effectively transfer them to each pyramid-level feature, thus effectively improving the segmentation effectiveness between different semantic objects. Secondly, the SMCM we designed can effectively extract multi-scale information and generate high-resolution feature maps with high-level semantic information, thus helping to segment objects in small and varying sizes. Without bells and whistles, the mIoU scores of the proposed PGNet on the iSAID dataset and ISPRS Vaihingn dataset are 1.49% and 2.40% higher than FactSeg, respectively.},
DOI = {10.3390/rs14174219}
}

@ARTICLE{9762698,
  author={Bi, Xiuli and Shuai, Chao and Liu, Bo and Xiao, Bin and Li, Weisheng and Gao, Xinbo},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Privacy-Preserving Color Image Feature Extraction by Quaternion Discrete Orthogonal Moments}, 
  year={2022},
  volume={17},
  number={},
  pages={1655-1668},
  abstract={To implement image storage and computation in cloud servers without violating users’ privacy, privacy-preserving feature extraction has been a new research interest. The existing works are mainly designed for grayscale images. For color images, they tend to convert them to grayscale images or obtain the results of the combination of single-channel processes. While the capabilities of features extracted from the encrypted color images will be affected if color information and inter-relationship between color channels are ignored. To fully preserve features of color images, we introduce quaternion theory to encode each color image and propose an improved vector homomorphic encryption scheme (IVHE) to encrypt quaternion-based color images. IVHE helps protect image content and keep vector characteristics of color images. Based on IVHE, the framework for feature extraction of privacy-preserving Quaternion Discrete Orthogonal Moments (PPQDOMs) is presented. Theoretical analyses prove that Quaternion Discrete Orthogonal Moments (QDOMs) can be extracted from the encrypted color images by PPQDOMs. Furthermore, we apply three common Discrete Orthogonal Moments to the proposed framework to evaluate its performance. Experimental results demonstrate that the proposed framework can protect color image content and perform well compared to QDOMs in image reconstruction and image recognition.},
  keywords={},
  doi={10.1109/TIFS.2022.3170268},
  ISSN={1556-6021},
  month={},}
